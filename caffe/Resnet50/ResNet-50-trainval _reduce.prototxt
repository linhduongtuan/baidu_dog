# Enter your network definition here.
# Use Shift+Enter to update the visualization.
name: "ResNet-50"
layer { 
	name: "data" 
	type: "Data" 
	top: "data" 
	top: "label" 
	include { 
		phase: TRAIN 
	}
	transform_param { 
		mean_file:"/home/zyh/PycharmProjects/baidu_dog/caffe/mean_crop.binaryproto"
		#scale: 0.0078125		
		mirror: true 
	#gamma_color_transform: true 
	# gamma_left: 0.8 #0.5 
	# gamma_right: 2.0 #1.5 
	# gamma_step_num: 8 #4 
	# brightness:true 
	# brightness_alpha_left: 0.7 
	# brightness_alpha_right: 1.2 
	# brightness_beta_left: -5.0
	# brightness_beta_right: 5.0 
	# brightness_alpha_num: 4 
	# brightness_beta_num: 4 
	# resize:true 
	# resize_ratio:14 googlenet__iter_80000.caffemodel
	# rotate:true 
	}
	data_param { 
		source: "/home/zyh/PycharmProjects/baidu_dog/caffe/train_crop_no_au"
		batch_size: 32 
		backend: LMDB 
	}
}
layer { 
	name: "data" 
	type: "Data" 
	top: "data" 
	top: "label" 
	include { 
		phase: TEST 
	}
	transform_param { 
		mean_file:"/home/zyh/PycharmProjects/baidu_dog/caffe/mean_crop.binaryproto"
		#scale: 0.0078125
		mirror: false 
	}
	data_param { 
		source: "/home/zyh/PycharmProjects/baidu_dog/caffe/val_crop_lmdb"
		batch_size: 15 
		backend: LMDB 
	}
}
layer { 
	bottom: "data" 
	top: "conv1" 
	name: "conv1" 
	type: "Convolution" 
	convolution_param { 
		num_output: 64 
		kernel_size: 7 
		pad: 3 
		stride: 2 
	}
}

layer { 
	bottom: "conv1" 
	top: "conv1" 
	name: "bn_conv1" 
	type: "BatchNorm" 
	batch_norm_param { 
		use_global_stats: false
	}
}

layer { 
	bottom: "conv1" 
	top: "conv1" 
	name: "scale_conv1" 
	type: "Scale" 
	scale_param { 
		bias_term: true 
	}
}

layer { 
	bottom: "conv1" 
	top: "conv1" 
	name: "conv1_relu" 
	type: "ReLU" 
}

layer { 
	bottom: "conv1" 
	top: "pool1" 
	name: "pool1" 
	type: "Pooling" 
	pooling_param { 
		kernel_size: 3 
		stride: 2 
		pool: MAX 
	}
}

layer { 
	bottom: "pool1" 
	top: "res2a_branch1" 
	name: "res2a_branch1" 
	type: "Convolution" 
	convolution_param { 
		num_output: 256 
		kernel_size: 1 
		pad: 0 
		stride: 1 
		bias_term: false 
	}
}

layer { 
	bottom: "res2a_branch1" 
	top: "res2a_branch1" 
	name: "bn2a_branch1" 
	type: "BatchNorm" 
	batch_norm_param { 
		use_global_stats: false
	}
}

layer { 
	bottom: "res2a_branch1" 
	top: "res2a_branch1" 
	name: "scale2a_branch1" 
	type: "Scale" 
	scale_param { 
		bias_term: true 
	}
}

layer { 
	bottom: "pool1" 
	top: "res2a_branch2a" 
	name: "res2a_branch2a" 
	type: "Convolution" 
	convolution_param { 
		num_output: 64 
		kernel_size: 1 
		pad: 0 
		stride: 1 
		bias_term: false 
	}
}

layer { 
	bottom: "res2a_branch2a" 
	top: "res2a_branch2a" 
	name: "bn2a_branch2a" 
	type: "BatchNorm" 
	batch_norm_param { 
		use_global_stats: false
	}
}

layer { 
	bottom: "res2a_branch2a" 
	top: "res2a_branch2a" 
	name: "scale2a_branch2a" 
	type: "Scale" 
	scale_param { 
		bias_term: true 
	}
}

layer { 
	bottom: "res2a_branch2a" 
	top: "res2a_branch2a" 
	name: "res2a_branch2a_relu" 
	type: "ReLU" 
}

layer { 
	bottom: "res2a_branch2a" 
	top: "res2a_branch2b" 
	name: "res2a_branch2b" 
	type: "Convolution" 
	convolution_param { 
		num_output: 64 
		kernel_size: 3 
		pad: 1 
		stride: 1 
		bias_term: false 
	}
}

layer { 
	bottom: "res2a_branch2b" 
	top: "res2a_branch2b" 
	name: "bn2a_branch2b" 
	type: "BatchNorm" 
	batch_norm_param { 
		use_global_stats: false
	}
}

layer { 
	bottom: "res2a_branch2b" 
	top: "res2a_branch2b" 
	name: "scale2a_branch2b" 
	type: "Scale" 
	scale_param { 
		bias_term: true 
	}
}

layer { 
	bottom: "res2a_branch2b" 
	top: "res2a_branch2b" 
	name: "res2a_branch2b_relu" 
	type: "ReLU" 
}

layer { 
	bottom: "res2a_branch2b" 
	top: "res2a_branch2c" 
	name: "res2a_branch2c" 
	type: "Convolution" 
	convolution_param { 
		num_output: 256 
		kernel_size: 1 
		pad: 0 
		stride: 1 
		bias_term: false 
	}
}

layer { 
	bottom: "res2a_branch2c" 
	top: "res2a_branch2c" 
	name: "bn2a_branch2c" 
	type: "BatchNorm" 
	batch_norm_param {
		use_global_stats: false
	}
}

layer { 
	bottom: "res2a_branch2c" 
	top: "res2a_branch2c" 
	name: "scale2a_branch2c" 
	type: "Scale" 
	scale_param { 
		bias_term: true 
	}
}

layer { 
	bottom: "res2a_branch1" 
	bottom: "res2a_branch2c" 
	top: "res2a" 
	name: "res2a" 
	type: "Eltwise" 
}

layer { 
	bottom: "res2a" 
	top: "res2a" 
	name: "res2a_relu" 
	type: "ReLU" 
}

layer { 
	bottom: "res2a" 
	top: "res2b_branch2a" 
	name: "res2b_branch2a" 
	type: "Convolution" 
	convolution_param { 
		num_output: 64 
		kernel_size: 1 
		pad: 0 
		stride: 1 
		bias_term: false 
	}
}

layer { 
	bottom: "res2b_branch2a" 
	top: "res2b_branch2a" 
	name: "bn2b_branch2a" 
	type: "BatchNorm" 
	batch_norm_param {
		use_global_stats: false
	}
}

layer { 
	bottom: "res2b_branch2a" 
	top: "res2b_branch2a" 
	name: "scale2b_branch2a"
	type: "Scale"
	scale_param { 
		bias_term: true 
	}
}

layer { 
	bottom: "res2b_branch2a" 
	top: "res2b_branch2a" 
	name: "res2b_branch2a_relu" 
	type: "ReLU" 
}

layer { 
	bottom: "res2b_branch2a" 
	top: "res2b_branch2b" 
	name: "res2b_branch2b" 
	type: "Convolution" 
	convolution_param { 
		num_output: 64 
		kernel_size: 3 
		pad: 1 
		stride: 1 
		bias_term: false 
	}
}

layer { 
	bottom: "res2b_branch2b" 
	top: "res2b_branch2b" 
	name: "bn2b_branch2b" 
	type: "BatchNorm" 
	batch_norm_param { 
		use_global_stats: false
	}
}

layer { 
	bottom: "res2b_branch2b" 
	top: "res2b_branch2b" 
	name: "scale2b_branch2b" 
	type: "Scale" 
	scale_param { 
		bias_term: true 
	}
}

layer { 
	bottom: "res2b_branch2b" 
	top: "res2b_branch2b" 
	name: "res2b_branch2b_relu"
	type: "ReLU" 
}

layer { 
	bottom: "res2b_branch2b"
	top: "res2b_branch2c" 
	name: "res2b_branch2c" 
	type: "Convolution" 
	convolution_param { 
		num_output: 256 
		kernel_size: 1 
		pad: 0 
		stride: 1 
		bias_term: false 
	}
}

layer { 
	bottom: "res2b_branch2c" 
	top: "res2b_branch2c" 
	name: "bn2b_branch2c" 
	type: "BatchNorm" 
	batch_norm_param { 
		use_global_stats: false
	}
}

layer { 
	bottom: "res2b_branch2c" 
	top: "res2b_branch2c" 
	name: "scale2b_branch2c" 
	type: "Scale" 
	scale_param { 
		bias_term: true 
	}
}

layer { 
	bottom: "res2a" 
	bottom: "res2b_branch2c" 
	top: "res2b" 
	name: "res2b" 
	type: "Eltwise" 
}

layer { 
	bottom: "res2b" 
	top: "res2b" 
	name: "res2b_relu" 
	type: "ReLU" 
}

layer { 
	bottom: "res2b" 
	top: "res2c_branch2a" 
	name: "res2c_branch2a" 
	type: "Convolution" 
	convolution_param { 
		num_output: 64 
		kernel_size: 1 
		pad: 0 
		stride: 1 
		bias_term: false 
	}
}

layer { 
	bottom: "res2c_branch2a" 
	top: "res2c_branch2a" 
	name: "bn2c_branch2a" 
	type: "BatchNorm" 
	batch_norm_param { 
		use_global_stats: false
	}
}

layer { 
	bottom: "res2c_branch2a" 
	top: "res2c_branch2a" 
	name: "scale2c_branch2a" 
	type: "Scale" 
	scale_param { 
		bias_term: true 
	}
}

layer { 
	bottom: "res2c_branch2a" 
	top: "res2c_branch2a" 
	name: "res2c_branch2a_relu" 
	type: "ReLU" 
}

layer { 
	bottom: "res2c_branch2a" 
	top: "res2c_branch2b" 
	name: "res2c_branch2b" 
	type: "Convolution" 
	convolution_param { 
		num_output: 64 
		kernel_size: 3 
		pad: 1 
		stride: 1 
		bias_term: false 
	}
}

layer { 
	bottom: "res2c_branch2b" 
	top: "res2c_branch2b" 
	name: "bn2c_branch2b" 
	type: "BatchNorm" 
	batch_norm_param { 
		use_global_stats: false
	}
}

layer { 
	bottom: "res2c_branch2b" 
	top: "res2c_branch2b" 
	name: "scale2c_branch2b" 
	type: "Scale" 
	scale_param { 
		bias_term: true 
	}
}

layer { 
	bottom: "res2c_branch2b" 
	top: "res2c_branch2b" 
	name: "res2c_branch2b_relu" 
	type: "ReLU" 
}

layer { 
	bottom: "res2c_branch2b" 
	top: "res2c_branch2c" 
	name: "res2c_branch2c" 
	type: "Convolution" 
	convolution_param { 
		num_output: 256 
		kernel_size: 1 
		pad: 0 
		stride: 1 
		bias_term: false 
	}
}

layer { 
	bottom: "res2c_branch2c" 
	top: "res2c_branch2c" 
	name: "bn2c_branch2c" 
	type: "BatchNorm" 
	batch_norm_param { 
		use_global_stats: false
	}
}

layer { 
	bottom: "res2c_branch2c" 
	top: "res2c_branch2c" 
	name: "scale2c_branch2c" 
	type: "Scale" 
	scale_param {
		bias_term: true 
	}
}

layer { 
	bottom: "res2b" 
	bottom: "res2c_branch2c" 
	top: "res2c" 
	name: "res2c" 
	type: "Eltwise" 
}

layer { 
	bottom: "res2c" 
	top: "res2c" 
	name: "res2c_relu" 
	type: "ReLU" 
}

layer { 
	bottom: "res2c" 
	top: "res3a_branch1" 
	name: "res3a_branch1" 
	type: "Convolution" 
	convolution_param { 
		num_output: 512 
		kernel_size: 1 
		pad: 0 
		stride: 2 
		bias_term: false 
	}
}

layer { 
	bottom: "res3a_branch1" 
	top: "res3a_branch1"
	name: "bn3a_branch1" 
	type: "BatchNorm" 
	batch_norm_param { 
		use_global_stats: false
	}
}

layer { 
	bottom: "res3a_branch1"
	top: "res3a_branch1" 
	name: "scale3a_branch1" 
	type: "Scale" 
	scale_param { 
		bias_term: true 
	}
}

layer { 
	bottom: "res2c" 
	top: "res3a_branch2a" 
	name: "res3a_branch2a" 
	type: "Convolution" 
	convolution_param { 
		num_output: 128 
		kernel_size: 1 
		pad: 0 
		stride: 2 
		bias_term: false 
	}
}

layer { 
	bottom: "res3a_branch2a" 
	top: "res3a_branch2a" 
	name: "bn3a_branch2a" 
	type: "BatchNorm" 
	batch_norm_param { 
		use_global_stats: false
	}
}

layer { 
	bottom: "res3a_branch2a" 
	top: "res3a_branch2a" 
	name: "scale3a_branch2a" 
	type: "Scale" 
	scale_param { 
		bias_term: true 
	}
}

layer { 
	bottom: "res3a_branch2a" 
	top: "res3a_branch2a" 
	name: "res3a_branch2a_relu"
	type: "ReLU" 
}

layer { 
	bottom: "res3a_branch2a" 
	top: "res3a_branch2b" 
	name: "res3a_branch2b" 
	type: "Convolution" 
	convolution_param { 
		num_output: 128 
		kernel_size: 3 
		pad: 1 
		stride: 1 
		bias_term: false 
	}
}

layer { 
	bottom: "res3a_branch2b" 
	top: "res3a_branch2b" 
	name: "bn3a_branch2b" 
	type: "BatchNorm" 
	batch_norm_param { 
		use_global_stats: false
	}
}

layer { 
	bottom: "res3a_branch2b" 
	top: "res3a_branch2b" 
	name: "scale3a_branch2b" 
	type: "Scale" 
	scale_param { 
		bias_term: true 
	}
}

layer { 
	bottom: "res3a_branch2b" 
	top: "res3a_branch2b" 
	name: "res3a_branch2b_relu" 
	type: "ReLU" 
}

layer { 
	bottom: "res3a_branch2b" 
	top: "res3a_branch2c" 
	name: "res3a_branch2c" 
	type: "Convolution" 
	convolution_param { 
		num_output: 512 
		kernel_size: 1 
		pad: 0 
		stride: 1 
		bias_term: false 
	}
}

layer { 
	bottom: "res3a_branch2c" 
	top: "res3a_branch2c" 
	name: "bn3a_branch2c" 
	type: "BatchNorm" 
	batch_norm_param { 
		use_global_stats: false
	}
}

layer { 
	bottom: "res3a_branch2c" 
	top: "res3a_branch2c" 
	name: "scale3a_branch2c" 
	type: "Scale" 
	scale_param { 
		bias_term: true 
	}
}

layer { 
	bottom: "res3a_branch1" 
	bottom: "res3a_branch2c" 
	top: "res3a" 
	name: "res3a" 
	type: "Eltwise" 
}

layer { 
	bottom: "res3a" 
	top: "res3a" 
	name: "res3a_relu" 
	type: "ReLU" 
}

layer { 
	bottom: "res3a" 
	top: "res3b_branch2a" 
	name: "res3b_branch2a" 
	type: "Convolution" 
	convolution_param { 
		num_output: 128 
		kernel_size: 1 
		pad: 0 
		stride: 1 
		bias_term: false 
	}
}

layer { 
	bottom: "res3b_branch2a" 
	top: "res3b_branch2a" 
	name: "bn3b_branch2a"
	type: "BatchNorm"
	batch_norm_param { 
		use_global_stats: false
	}
}

layer { 
	bottom: "res3b_branch2a" 
	top: "res3b_branch2a" 
	name: "scale3b_branch2a" 
	type: "Scale" 
	scale_param { 
		bias_term: true 
	}
}

layer { 
	bottom: "res3b_branch2a" 
	top: "res3b_branch2a" 
	name: "res3b_branch2a_relu" 
	type: "ReLU" 
}

layer { 
	bottom: "res3b_branch2a" 
	top: "res3b_branch2b" 
	name: "res3b_branch2b" 
	type: "Convolution" 
	convolution_param { 
		num_output: 128 
		kernel_size: 3 
		pad: 1 
		stride: 1 
		bias_term: false 
	}
}

layer { 
	bottom: "res3b_branch2b" 
	top: "res3b_branch2b" 
	name: "bn3b_branch2b" 
	type: "BatchNorm" 
	batch_norm_param { 
		use_global_stats: false
	}
}

layer { 
	bottom: "res3b_branch2b" 
	top: "res3b_branch2b" 
	name: "scale3b_branch2b" 
	type: "Scale" 
	scale_param { 
		bias_term: true 
	}
}

layer { 
	bottom: "res3b_branch2b" 
	top: "res3b_branch2b" 
	name: "res3b_branch2b_relu" 
	type: "ReLU" 
}

layer { 
	bottom: "res3b_branch2b" 	
	top: "res3b_branch2c" 
	name: "res3b_branch2c" 
	type: "Convolution" 
	convolution_param { 
		num_output: 512 
		kernel_size: 1 
		pad: 0 
		stride: 1 
		bias_term: false 
	}
}

layer { 
	bottom: "res3b_branch2c" 
	top: "res3b_branch2c" 
	name: "bn3b_branch2c" 
	type: "BatchNorm" 
	batch_norm_param { 
		use_global_stats: false
	}
}

layer { 
	bottom: "res3b_branch2c" 
	top: "res3b_branch2c" 
	name: "scale3b_branch2c" 
	type: "Scale" 
	scale_param { 
		bias_term: true 
	}
}

layer { 
	bottom: "res3a" 
	bottom: "res3b_branch2c" 
	top: "res3b" 
	name: "res3b" 
	type: "Eltwise" 
}

layer { 
	bottom: "res3b" 
	top: "res3b" 
	name: "res3b_relu" 
	type: "ReLU" 
}

layer { 
	bottom: "res3b" 
	top: "res3c_branch2a" 
	name: "res3c_branch2a" 
	type: "Convolution" 
	convolution_param { 
		num_output: 128 
		kernel_size: 1 
		pad: 0 
		stride: 1 
		bias_term: false 
	}
}

layer { 
	bottom: "res3c_branch2a" 
	top: "res3c_branch2a" 
	name: "bn3c_branch2a" 
	type: "BatchNorm" 
	batch_norm_param { 
		use_global_stats: false
	}
}

layer { 
	bottom: "res3c_branch2a" 
	top: "res3c_branch2a" 
	name: "scale3c_branch2a" 
	type: "Scale" 
	scale_param { 
		bias_term: true 
	}
}

layer { 
	bottom: "res3c_branch2a" 
	top: "res3c_branch2a" 
	name: "res3c_branch2a_relu" 
	type: "ReLU" 
}

layer { 
	bottom: "res3c_branch2a" 
	top: "res3c_branch2b" 
	name: "res3c_branch2b" 
	type: "Convolution" 
	convolution_param { 
		num_output: 128 
		kernel_size: 3 
		pad: 1 
		stride: 1 
		bias_term: false 
	}
}

layer { 
	bottom: "res3c_branch2b" 
	top: "res3c_branch2b" 
	name: "bn3c_branch2b" 
	type: "BatchNorm"
	batch_norm_param { 
		use_global_stats: false
	}
}

layer { 
	bottom: "res3c_branch2b"
	top: "res3c_branch2b"
	name: "scale3c_branch2b" 
	type: "Scale" 
	scale_param { 
		bias_term: true 
	}
}

layer { 
	bottom: "res3c_branch2b" 
	top: "res3c_branch2b" 
	name: "res3c_branch2b_relu"
	type: "ReLU" 
}

layer { 
	bottom: "res3c_branch2b" 
	top: "res3c_branch2c" 
	name: "res3c_branch2c" 
	type: "Convolution" 
	convolution_param { 
		num_output: 512 
		kernel_size: 1 
		pad: 0 
		stride: 1 
		bias_term: false 
	}
}

layer { 
	bottom: "res3c_branch2c" 
	top: "res3c_branch2c"
	name: "bn3c_branch2c" 
	type: "BatchNorm" 
	batch_norm_param { 
		use_global_stats: false
	}
}

layer { 
	bottom: "res3c_branch2c" 
	top: "res3c_branch2c" 
	name: "scale3c_branch2c" 
	type: "Scale" 
	scale_param { 
		bias_term: true
	}
}

layer { 
	bottom: "res3b" 
	bottom: "res3c_branch2c"
	top: "res3c" 
	name: "res3c" 
	type: "Eltwise" 
}

layer { 
	bottom: "res3c" 
	top: "res3c" 
	name: "res3c_relu" 
	type: "ReLU" 
}


layer { 
	bottom: "res3c" 
	top: "pool5" 
	name: "pool5" 
	type: "Pooling" 
	pooling_param { 
		kernel_size: 7 
		stride: 1 
		pool: MAX 
	}
}

layer { 
	bottom: "pool5" 
	top: "newfc" 
	name: "newfc" 
	type: "InnerProduct" 
	param { 
		lr_mult: 1 
		decay_mult: 2 
	}
    inner_product_param { 
		num_output: 512 
	}
}

layer {
  name: "dropout"
  type: "Dropout"
  bottom: "newfc"
  top: "newfc"
  dropout_param {
    dropout_ratio: 0.2
  }
}

layer { 
	bottom: "newfc" 
	top: "fc204_ft" 
	name: "fc204_ft" 
	type: "InnerProduct" 
	param { 
		lr_mult: 1 
		decay_mult: 2 
	}
    inner_product_param { 
		num_output: 100 
	}
}
layer { 
	name: "accuracy-1" 
	type: "Accuracy" 
	bottom: "fc204_ft" 
	bottom: "label" 
	top: "accuracy-1" 
	include { 
		phase: TEST 
	}
}
layer { 
	name: "sofimax_loss" 
	type: "SoftmaxWithLoss" 	
	bottom: "fc204_ft"
	bottom: "label" 
	top: "loss" 
}
############## center loss ###############
#layer {
#  name: "center_loss"
#  type: "CenterLoss"
#  bottom: "newfc"
#  bottom: "label"
#  top: "center_loss"
#  param {
#    lr_mult: 10
#    decay_mult: 10 
#  }
#  center_loss_param {
#    num_output: 100
#    center_filler {
#      type: "xavier"
#    }
#  }
#  loss_weight: 0.08
#}
#layer { 
	# bottom: "fc204_1" 
	# top: "prob" 
	# name: "prob" 
	# type: "Softmax" 
#}
